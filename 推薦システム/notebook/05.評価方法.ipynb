{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 評価方法\n",
    "\n",
    "参考文献\n",
    "\n",
    " - [レコメンドつれづれ　～第3回 レコメンド精度の評価方法を学ぶ～ - Platinum Data Blog by BrainPad](http://blog.brainpad.co.jp/entry/2017/08/25/140000)\n",
    " - Deepak K. Agarwal & Bee-Chung Chen[2018]「第4章 推薦システムの評価」『推薦システム - 統計的機械学習の理論と実践 - 』共立出版株式会社"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-27T12:27:23.026310Z",
     "start_time": "2019-10-27T12:27:20.116844Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 日本語フォントを設定\n",
    "font = {'family': 'IPAexGothic'}\n",
    "mpl.rc('font', **font)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# オフライン評価"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 予測の評価指標\n",
    "レビューや口コミのようにユーザの嗜好が数段回（1から5など）の<strong style=\"color: red;\">レーティング,数値</strong>で表されるケースでの評価指標を紹介します。ユーザのレーティングをレコメンドシステムがいかに正確に予測できるかを評価します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 平均絶対誤差(Mean Abusolute Error, MAE)\n",
    "算出時は、予測値、実測値の両方の値が存在するユーザ-アイテムのペアのみを対象として次のように計算します。\n",
    "$$\n",
    "\\mathrm {MAE} = \\frac {1}{n} \\sum _{i=1}^{n}{\\left| \\hat {r}_{i} - r_{i} \\right|}\n",
    "$$\n",
    "\n",
    " - $\\hat {r}_{i}$ : レーティングの予測値\n",
    " - $r_{i}$ : レーティングの実測値\n",
    " - $n$ : ユーザ-アイテムペアの数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 二乗平均平方根誤差(Root Mean Squared Error, RMSE)\n",
    "$$\n",
    "\\mathrm {RMSE} = \\sqrt { \\frac {1}{n} \\sum _{i=1}^{n}{\\left( \\hat {r}_{i} - r_{i} \\right)^{2}} }\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分類の評価指標\n",
    "次にECサイトのように、得られるユーザの利用履歴が購入・カート投入の有無といった<strong style=\"color:red;\">2値</strong>で表される場合の評価指標を紹介します。評価の大まかなコンセプトはユーザが好む（購買する）と予測したアイテムと、実際にユーザが好んだ（購買した）アイテムを比較することです。レコメンドでは予測した全アイテムに対する精度を評価するのではなく、TopNに対する評価が使われます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision(適合率)\n",
    "> レコメンドリストにあるアイテムのうちユーザが嗜好したアイテム（適合アイテム）の割合。ここでの「レコメンドリストにあるアイテム数」は、TopNのNに該当します。つまりTopNアイテムのうち、何割がユーザにクリック・購入されたかということです。レコメンドの評価ではTopNに対するPrecisionということで、明示的にPrecision@Nと呼ばれることがあります。\n",
    "\n",
    "$$\n",
    "Precision@N = \\frac {\\left| a \\cap p_{N} \\right|}{N}\n",
    "$$\n",
    "\n",
    " - $N$ : 考慮する上位ランキングの数\n",
    " - $a$ : ユーザーが嗜好したアイテム集合\n",
    " - $N$ : TopNのレコメンドリスト\n",
    "\n",
    "混同行列を用いて表すと\n",
    "\n",
    "$$\n",
    "Precision = \\frac {TP}{TP + FP}\n",
    "$$\n",
    "\n",
    " - $TP(True Positive)$ : ユーザが好きなものをTopNでレコメンドできた数\n",
    " - $FP(False Positive)$ : ユーザが好きでないものを間違ってレコメンドした数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recall(再現率)\n",
    "> Recallは、ユーザが実際に嗜好したアイテムのうち、レコメンドリストでカバーできたかの割合です。 Precisionと並んで最もよく利用される指標の一つとなります。 \n",
    "\n",
    "$$\n",
    "Recall@N = \\frac {\\left| a \\cap p_{N} \\right|}{\\left| a \\right|}\n",
    "$$\n",
    "\n",
    " - $N$ : 考慮する上位ランキングの数\n",
    " - $a$ : ユーザが嗜好したアイテム集合\n",
    " - $p_{N}$ : TopNのレコメンドリスト\n",
    " \n",
    "混同行列を用いて表すと\n",
    "\n",
    "$$\n",
    "Recall = \\frac {TP}{TP + FN}\n",
    "$$\n",
    "\n",
    " - $TP(True Positive)$ : ユーザが好きなものをTopNでレコメンドできた数\n",
    " - $FN(False Negative)$ : ユーザが好きなものを間違ってレコメンドしなかった数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F値\n",
    "$$\n",
    "F1 = \\frac {2 Recall \\times Precision}{Recall + Precision}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ランキングの評価指標\n",
    "レコメンドで最終的にユーザに提示されるのはおすすめ度の高い上位数アイテム（TopN）なので、ユーザの嗜好が高い順にアイテムを正しく並べ変えるタスクと捉えることができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PR曲線"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC曲線"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MRR(Mean Reciprocal Rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAP(Mean Average Precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nDCG(normalized Discounted Cumulative Gain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## カバレッジの評価指標\n",
    "ここまでいくつかの評価指標を見てきましたが、レコメンドを評価する際に精度だけを見ていれば良いのかという問題があります。\n",
    "\n",
    "> よく挙げられる例として、人気ランキング上位の商品ばかりがレコメンドされたり、牛乳と卵がよく買われるスーパーマーケットで牛乳と卵をおすすめされるケースがあります。これら人気の高い商品や、一般によく購入する傾向にある商品をレコメンドしていれば、精度指標はある程度高くなることは間違いないですが、購入されることが自明な商品ばかりをレコメンドしていてもあまりレコメンドの有り難みはなさそうです。\n",
    "\n",
    "レコメンドされるアイテムには幅の広さや目新しさのようなものが求められることがあります。ここではレコメンドの幅広さを測る指標としてカバレッジを紹介します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### カタログカバレッジ(Catalogue Coverage)\n",
    "カタログカバレッジは、利用可能な全アイテムのうち、1回のレコメンドでどのくらい多くのアイテムをレコメンドできたか示します。\n",
    "\n",
    " - レコメンドのアイテム方向への広がりやカバー率を表し、この値が大きいほど幅広いアイテムをレコメンドできたことになります。\n",
    "\n",
    "$$\n",
    "Catalogue Coverage = \\frac {\\left| S_{r} \\right|}{\\left| S_{a} \\right|}\n",
    "$$\n",
    "\n",
    " - $S_{r}$ : 1回のレコメンドでユーザにおすすめされたアイテム集合\n",
    " - $S_{a}$ : 利用可能な全アイテム集合\n",
    "\n",
    "いくら幅広くてもユーザが嗜好しないアイテムをおすすめしても仕方ないということで、適合アイテムのみに対象を絞った<strong>適合カタログカバレッジ（Weighted Catalogue Coverage）</strong>を用いることもあるようです。\n",
    "\n",
    "$$\n",
    "Weighted Catalogue Coverage = \\frac {\\left| S_{r} \\cap S_{s} \\right|}{\\left| S_{s} \\right|}\n",
    "$$\n",
    "\n",
    " - $S_{s}$ : 適合アイテム集合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ユーザカバレッジ(Prediction Coverage)\n",
    "ユーザカバレッジは、ユーザに対するカバー率です。全対象ユーザのうち、1回のレコメンドでどのくらい多くのユーザに対してレコメンドできたか示します。\n",
    "\n",
    " - レコメンドのユーザ方向への広がりを表し、この値が大きいほど幅広いユーザに対してレコメンドできたことになります。\n",
    "\n",
    "$$\n",
    "Prediction Coverage = \\frac {\\left| S_{p} \\right|}{\\left| S_{u} \\right|}\n",
    "$$\n",
    "\n",
    " - $S_{p}$ : 1回のレコメンドでユーザにおすすめされたユーザ集合\n",
    " - $S_{u}$ : 利用可能な全ユーザ集合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "カバレッジは、レコメンドの幅広さの一つとして利用されます。またアルゴリズムがどの程度のアイテムおよびユーザに対してレコメンドを生成できるかという、アルゴリズムのコールドスタートへの対応も評価できます。一般にレコメンドの利用履歴はスパースなものが多いため、協調フィルタリングなどコールドスタートへの対応が難しいアルゴリズムでは、レコメンドリストを作成できないユーザやアイテムが多く存在する可能性がありますので広がりにも注意して評価する必要があります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## その他\n",
    "レコメンドの目的の一つが「ユーザを長期間魅了し続けること（LTVを上げる）」だった場合、利用履歴にあるユーザの嗜好と近いからと言って、あまり同じような商品ばかりをレコメンドしていてもユーザは飽きてしまうかもしれません。ここでアイテムに対する意外性や出会いのようなものが必要、という考えが出てきます。ここまで紹介したスタンダードな評価指標以外に最近は、目新しさ（Novelty）やセレンディピティ（Serendipity）、多様性（Diversity）という、意外性や驚きみたいなものを重要視する動きがあります。これらを定量化してレコメンドに活かしていこうという試みも進んでいますので、気になる方は調べてみてください。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
