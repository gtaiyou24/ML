{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 文書のベクトル化\n",
    "\n",
    " - 頻度ベクトル(Bag-of-Words)\n",
    " - 二値ベクトル\n",
    " - TF-IDFベクトル(頻度ベクトルの各要素に重み付けしたベクトル)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BoW(Bag-of-Words)ベクトル\n",
    "BoWベクトルの背景にある考え方\n",
    "\n",
    "> 1. 文書の集合全体から、たとえば単語という一意な**トークン**(token)からなる**語彙**(vocabulary)を作成する\n",
    "> 2. 各文書での各単語の出現回数を含んだ特徴ベクトルを構築する\n",
    "\n",
    "構築されたBoWベクトルの大半の成分は0になるため、**疎ベクトル**(sparse vector)と呼ばれる。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\boldsymbol {x} = \\left( \\mathrm {tf} \\left( t_{1}, d \\right) , \\dots, \\mathrm {tf} \\left( t_{i}, d \\right), \\dots, \\mathrm {tf} \\left( t_{n}, d \\right) \\right)\n",
    "$$\n",
    "\n",
    " - $\\mathrm {tf} \\left( t_{i}, d \\right)$ : 文書$d$における単語$t$の出現回数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vectorizer = CountVectorizer()\n",
    "docs = np.array([\n",
    "    'The sun is shining',\n",
    "    'The weather is sweet',\n",
    "    'The sun is shining, the weather is sweet, and one and one is two',\n",
    "])\n",
    "bag = count_vectorizer.fit_transform(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "two        1\n",
       "and        2\n",
       "one        2\n",
       "shining    2\n",
       "sun        2\n",
       "sweet      2\n",
       "weather    2\n",
       "the        4\n",
       "is         5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_freq_ser = pd.Series(\n",
    "    bag.toarray().sum(axis=0),\n",
    "    index=count_vectorizer.get_feature_names()\n",
    ")\n",
    "\n",
    "word_freq_ser.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>is</th>\n",
       "      <th>one</th>\n",
       "      <th>shining</th>\n",
       "      <th>sun</th>\n",
       "      <th>sweet</th>\n",
       "      <th>the</th>\n",
       "      <th>two</th>\n",
       "      <th>weather</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   and  is  one  shining  sun  sweet  the  two  weather\n",
       "0    0   1    0        1    1      0    1    0        0\n",
       "1    0   1    0        0    0      1    1    0        1\n",
       "2    2   3    2        1    1      1    2    1        1"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_of_word_df = pd.DataFrame(\n",
    "    bag.toarray(),\n",
    "    columns=count_vectorizer.get_feature_names()\n",
    ")\n",
    "bag_of_word_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## TF-IDF(Term Frequency-Inverse Document Frequency)ベクトル\n",
    "BoWベクトルの各要素は、\"文書$d$に特定の単語$t_{i}$が何回現れるか、その回数を数えた\"だけの単純なものでした。このベクトルの問題は文書中に特定の単語が多く存在すればするほど、その単語に対する重要度が高くなるので、「です」「と」などといったどの文書にも出現しやすい単語の重要度が高くなってしまいます。\n",
    "\n",
    "これらの問題は次の方法によって解決します。\n",
    "\n",
    "”ある単語に対して、対象の文書中で出現した回数をカウントするのに加えて、その単語が**他の文書で**どれだけ出現するかをカウントし、その回数で割る（徐算する）”\n",
    "\n",
    "上記のようにすることで、特定の文書だけで現れやすい単語、つまり、他の文書ではあまり現れない単語には、特徴量として大きな値を設定することができます。\n",
    "\n",
    "$$\n",
    "\\boldsymbol {x}_{d} = \\left( \\mathrm {tf-idf} \\left( t_{1}, d \\right) , \\dots, \\mathrm {tf-idf} \\left( t_{i}, d \\right), \\dots, \\mathrm {tf-idf} \\left( t_{}, d \\right) \\right)\n",
    "$$\n",
    "\n",
    "\n",
    " - $\\mathrm {tf-idf} \\left( t_{i}, d \\right) = \\mathrm {tf}\\left( t_{i}, d \\right) \\times \\mathrm {idf} \\left( t_{i}, d \\right)$\n",
    "\n",
    "$$\n",
    "\\mathrm {idf}\\left( t_{i}, d \\right) = \\log {\\frac {n_{d}}{1 + \\mathrm {df}\\left( t_{i}, d \\right)}}\n",
    "$$\n",
    "\n",
    " - $n_{d}$ : 文書の総数\n",
    " - $\\mathrm {tf} \\left( t_{i}, d \\right)$ : 文書$d$における単語$t$の出現回数\n",
    "\n",
    "上記のTF-IDFで対数が使用されているのは、頻度の低い文書に過剰な重みが与えられないようにするためです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.43, 0.  , 0.56, 0.56, 0.  , 0.43, 0.  , 0.  ],\n",
       "       [0.  , 0.43, 0.  , 0.  , 0.  , 0.56, 0.43, 0.  , 0.56],\n",
       "       [0.5 , 0.45, 0.5 , 0.19, 0.19, 0.19, 0.3 , 0.25, 0.19]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tfidf = TfidfTransformer(use_idf=True, norm='l2', smooth_idf=True)\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "tfidf.fit_transform(count_vectorizer.transform(docs)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>is</th>\n",
       "      <th>one</th>\n",
       "      <th>shining</th>\n",
       "      <th>sun</th>\n",
       "      <th>sweet</th>\n",
       "      <th>the</th>\n",
       "      <th>two</th>\n",
       "      <th>weather</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.433708</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.558478</td>\n",
       "      <td>0.558478</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.433708</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.433708</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.558478</td>\n",
       "      <td>0.433708</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.558478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.502386</td>\n",
       "      <td>0.445076</td>\n",
       "      <td>0.502386</td>\n",
       "      <td>0.191039</td>\n",
       "      <td>0.191039</td>\n",
       "      <td>0.191039</td>\n",
       "      <td>0.296718</td>\n",
       "      <td>0.251193</td>\n",
       "      <td>0.191039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        and        is       one   shining       sun     sweet       the  \\\n",
       "0  0.000000  0.433708  0.000000  0.558478  0.558478  0.000000  0.433708   \n",
       "1  0.000000  0.433708  0.000000  0.000000  0.000000  0.558478  0.433708   \n",
       "2  0.502386  0.445076  0.502386  0.191039  0.191039  0.191039  0.296718   \n",
       "\n",
       "        two   weather  \n",
       "0  0.000000  0.000000  \n",
       "1  0.000000  0.558478  \n",
       "2  0.251193  0.191039  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_df = pd.DataFrame(\n",
    "    tfidf.fit_transform(count_vectorizer.transform(docs)).toarray(),\n",
    "    columns=count_vectorizer.get_feature_names()\n",
    ")\n",
    "tfidf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
