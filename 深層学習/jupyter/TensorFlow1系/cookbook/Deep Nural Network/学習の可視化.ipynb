{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 学習の可視化\n",
    "## TensorFlowによる実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taiyou/.pyenv/versions/anaconda3-5.0.1/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "/Users/taiyou/.pyenv/versions/anaconda3-5.0.1/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "/Users/taiyou/.pyenv/versions/anaconda3-5.0.1/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0  validation loss: 2.1558669  validation accuracy: 0.26725\n",
      "epoch: 1  validation loss: 0.8131207  validation accuracy: 0.768\n",
      "epoch: 2  validation loss: 0.51363796  validation accuracy: 0.85125\n",
      "epoch: 3  validation loss: 0.40519613  validation accuracy: 0.88725\n",
      "epoch: 4  validation loss: 0.3408817  validation accuracy: 0.90225\n",
      "epoch: 5  validation loss: 0.30277404  validation accuracy: 0.914\n",
      "epoch: 6  validation loss: 0.26965433  validation accuracy: 0.92175\n",
      "epoch: 7  validation loss: 0.25186813  validation accuracy: 0.9305\n",
      "epoch: 8  validation loss: 0.23474042  validation accuracy: 0.93325\n",
      "epoch: 9  validation loss: 0.22533228  validation accuracy: 0.9335\n",
      "epoch: 10  validation loss: 0.21379852  validation accuracy: 0.93875\n",
      "epoch: 11  validation loss: 0.20155106  validation accuracy: 0.94375\n",
      "epoch: 12  validation loss: 0.20540118  validation accuracy: 0.94075\n",
      "epoch: 13  validation loss: 0.18442798  validation accuracy: 0.948\n",
      "epoch: 14  validation loss: 0.19221994  validation accuracy: 0.9455\n",
      "epoch: 15  validation loss: 0.18167248  validation accuracy: 0.95\n",
      "epoch: 16  validation loss: 0.17690219  validation accuracy: 0.95225\n",
      "epoch: 17  validation loss: 0.1770504  validation accuracy: 0.95075\n",
      "epoch: 18  validation loss: 0.16998078  validation accuracy: 0.9545\n",
      "epoch: 19  validation loss: 0.17046326  validation accuracy: 0.95225\n",
      "epoch: 20  validation loss: 0.16714188  validation accuracy: 0.95475\n",
      "epoch: 21  validation loss: 0.16665687  validation accuracy: 0.95425\n",
      "epoch: 22  validation loss: 0.16041708  validation accuracy: 0.95525\n",
      "epoch: 23  validation loss: 0.15855236  validation accuracy: 0.9585\n",
      "epoch: 24  validation loss: 0.15041552  validation accuracy: 0.9595\n",
      "epoch: 25  validation loss: 0.15221725  validation accuracy: 0.96025\n",
      "epoch: 26  validation loss: 0.15488507  validation accuracy: 0.96175\n",
      "epoch: 27  validation loss: 0.15251549  validation accuracy: 0.961\n",
      "epoch: 28  validation loss: 0.15054494  validation accuracy: 0.9585\n",
      "epoch: 29  validation loss: 0.15429148  validation accuracy: 0.96125\n",
      "epoch: 30  validation loss: 0.14869572  validation accuracy: 0.964\n",
      "epoch: 31  validation loss: 0.15499805  validation accuracy: 0.9595\n",
      "epoch: 32  validation loss: 0.15246592  validation accuracy: 0.96\n",
      "epoch: 33  validation loss: 0.15215927  validation accuracy: 0.96275\n",
      "epoch: 34  validation loss: 0.14504611  validation accuracy: 0.96275\n",
      "epoch: 35  validation loss: 0.14852378  validation accuracy: 0.96425\n",
      "epoch: 36  validation loss: 0.14871265  validation accuracy: 0.9635\n",
      "epoch: 37  validation loss: 0.14685602  validation accuracy: 0.96325\n",
      "epoch: 38  validation loss: 0.14678869  validation accuracy: 0.964\n",
      "epoch: 39  validation loss: 0.15447581  validation accuracy: 0.96425\n",
      "epoch: 40  validation loss: 0.15280874  validation accuracy: 0.96175\n",
      "epoch: 41  validation loss: 0.15573348  validation accuracy: 0.96\n",
      "epoch: 42  validation loss: 0.15451613  validation accuracy: 0.96175\n",
      "epoch: 43  validation loss: 0.15238962  validation accuracy: 0.9625\n",
      "epoch: 44  validation loss: 0.15102567  validation accuracy: 0.96325\n",
      "epoch: 45  validation loss: 0.14581442  validation accuracy: 0.96425\n",
      "epoch: 46  validation loss: 0.14803599  validation accuracy: 0.96525\n",
      "epoch: 47  validation loss: 0.14867923  validation accuracy: 0.96325\n",
      "epoch: 48  validation loss: 0.14484802  validation accuracy: 0.96575\n",
      "epoch: 49  validation loss: 0.15247767  validation accuracy: 0.96425\n",
      "accuracy:  0.9636\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(0)\n",
    "tf.set_random_seed(1234)\n",
    "\n",
    "\n",
    "def inference(x, keep_prob, n_in, n_hiddens, n_out):\n",
    "    def weight_variable(shape):\n",
    "        initial = tf.truncated_normal(shape, stddev=0.01)\n",
    "        return tf.Variable(initial)\n",
    "\n",
    "    def bias_variable(shape):\n",
    "        initial = tf.zeros(shape)\n",
    "        return tf.Variable(initial)\n",
    "\n",
    "    # 入力層 - 隠れ層、隠れ層 - 隠れ層\n",
    "    for i, n_hidden in enumerate(n_hiddens):\n",
    "        if i == 0:\n",
    "            input = x\n",
    "            input_dim = n_in\n",
    "        else:\n",
    "            input = output\n",
    "            input_dim = n_hiddens[i-1]\n",
    "\n",
    "        W = weight_variable([input_dim, n_hidden])\n",
    "        b = bias_variable([n_hidden])\n",
    "\n",
    "        h = tf.nn.relu(tf.matmul(input, W) + b)\n",
    "        output = tf.nn.dropout(h, keep_prob)\n",
    "\n",
    "    # 隠れ層 - 出力層\n",
    "    W_out = weight_variable([n_hiddens[-1], n_out])\n",
    "    b_out = bias_variable([n_out])\n",
    "    y = tf.nn.softmax(tf.matmul(output, W_out) + b_out)\n",
    "    return y\n",
    "\n",
    "\n",
    "def loss(y, t):\n",
    "    cross_entropy = \\\n",
    "        tf.reduce_mean(-tf.reduce_sum(\n",
    "                       t * tf.log(tf.clip_by_value(y, 1e-10, 1.0)),\n",
    "                       axis=1))\n",
    "    return cross_entropy\n",
    "\n",
    "\n",
    "def training(loss):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.01)\n",
    "    train_step = optimizer.minimize(loss)\n",
    "    return train_step\n",
    "\n",
    "\n",
    "def accuracy(y, t):\n",
    "    correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(t, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    '''\n",
    "    データの生成\n",
    "    '''\n",
    "    mnist = datasets.fetch_mldata('MNIST original', data_home='.')\n",
    "\n",
    "    n = len(mnist.data)\n",
    "    N = 30000  # MNISTの一部を使う\n",
    "    N_train = 20000\n",
    "    N_validation = 4000\n",
    "    indices = np.random.permutation(range(n))[:N]  # ランダムにN枚を選択\n",
    "\n",
    "    X = mnist.data[indices]\n",
    "    y = mnist.target[indices]\n",
    "    Y = np.eye(10)[y.astype(int)]  # 1-of-K 表現に変換\n",
    "\n",
    "    X_train, X_test, Y_train, Y_test = \\\n",
    "        train_test_split(X, Y, train_size=N_train)\n",
    "\n",
    "    X_train, X_validation, Y_train, Y_validation = \\\n",
    "        train_test_split(X_train, Y_train, test_size=N_validation)\n",
    "\n",
    "    '''\n",
    "    モデル設定\n",
    "    '''\n",
    "    n_in = len(X[0])\n",
    "    n_hiddens = [200, 200, 200]  # 各隠れ層の次元数\n",
    "    n_out = len(Y[0])\n",
    "    p_keep = 0.5\n",
    "\n",
    "    x = tf.placeholder(tf.float32, shape=[None, n_in])\n",
    "    t = tf.placeholder(tf.float32, shape=[None, n_out])\n",
    "    keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "    y = inference(x, keep_prob, n_in=n_in, n_hiddens=n_hiddens, n_out=n_out)\n",
    "    loss = loss(y, t)\n",
    "    train_step = training(loss)\n",
    "\n",
    "    accuracy = accuracy(y, t)\n",
    "\n",
    "    history = {\n",
    "        'val_loss': [],\n",
    "        'val_acc': []\n",
    "    }\n",
    "\n",
    "    '''\n",
    "    モデル学習\n",
    "    '''\n",
    "    epochs = 50\n",
    "    batch_size = 200\n",
    "\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess = tf.Session()\n",
    "    sess.run(init)\n",
    "\n",
    "    n_batches = N_train // batch_size\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        X_, Y_ = shuffle(X_train, Y_train)\n",
    "\n",
    "        for i in range(n_batches):\n",
    "            start = i * batch_size\n",
    "            end = start + batch_size\n",
    "\n",
    "            sess.run(train_step, feed_dict={\n",
    "                x: X_[start:end],\n",
    "                t: Y_[start:end],\n",
    "                keep_prob: p_keep\n",
    "            })\n",
    "\n",
    "        # 検証データを用いた評価\n",
    "        val_loss = loss.eval(session=sess, feed_dict={\n",
    "            x: X_validation,\n",
    "            t: Y_validation,\n",
    "            keep_prob: 1.0\n",
    "        })\n",
    "        val_acc = accuracy.eval(session=sess, feed_dict={\n",
    "            x: X_validation,\n",
    "            t: Y_validation,\n",
    "            keep_prob: 1.0\n",
    "        })\n",
    "\n",
    "        # 検証データに対する学習の進み具合を記録\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "\n",
    "        print('epoch:', epoch,\n",
    "              ' validation loss:', val_loss,\n",
    "              ' validation accuracy:', val_acc)\n",
    "\n",
    "    '''\n",
    "    学習の進み具合を可視化\n",
    "    '''\n",
    "    plt.rc('font', family='serif')\n",
    "    fig = plt.figure()\n",
    "    ax_acc = fig.add_subplot(111)\n",
    "    ax_acc.plot(range(epochs), history['val_acc'],\n",
    "                label='acc', color='black')\n",
    "    ax_loss = ax_acc.twinx()\n",
    "    ax_loss.plot(range(epochs), history['val_loss'],\n",
    "                 label='loss', color='gray')\n",
    "    plt.xlabel('epochs')\n",
    "    # plt.show()\n",
    "    plt.savefig('mnist_tensorflow.eps')\n",
    "\n",
    "    '''\n",
    "    予測精度の評価\n",
    "    '''\n",
    "    accuracy_rate = accuracy.eval(session=sess, feed_dict={\n",
    "        x: X_test,\n",
    "        t: Y_test,\n",
    "        keep_prob: 1.0\n",
    "    })\n",
    "    print('accuracy: ', accuracy_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kerasによる実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/taiyou/.pyenv/versions/anaconda3-5.0.1/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16000 samples, validate on 4000 samples\n",
      "Epoch 1/50\n",
      "16000/16000 [==============================] - 1s 89us/step - loss: 2.2604 - acc: 0.1546 - val_loss: 2.0650 - val_acc: 0.4370\n",
      "Epoch 2/50\n",
      "16000/16000 [==============================] - 1s 63us/step - loss: 1.4282 - acc: 0.5261 - val_loss: 0.7209 - val_acc: 0.7718\n",
      "Epoch 3/50\n",
      "16000/16000 [==============================] - 1s 78us/step - loss: 0.8070 - acc: 0.7351 - val_loss: 0.4907 - val_acc: 0.8597\n",
      "Epoch 4/50\n",
      "16000/16000 [==============================] - 1s 61us/step - loss: 0.6134 - acc: 0.8109 - val_loss: 0.3994 - val_acc: 0.8833\n",
      "Epoch 5/50\n",
      "16000/16000 [==============================] - 1s 52us/step - loss: 0.5117 - acc: 0.8460 - val_loss: 0.3328 - val_acc: 0.9043\n",
      "Epoch 6/50\n",
      "16000/16000 [==============================] - 1s 56us/step - loss: 0.4365 - acc: 0.8709 - val_loss: 0.2996 - val_acc: 0.9110\n",
      "Epoch 7/50\n",
      "16000/16000 [==============================] - 1s 60us/step - loss: 0.3893 - acc: 0.8867 - val_loss: 0.2586 - val_acc: 0.9227\n",
      "Epoch 8/50\n",
      "16000/16000 [==============================] - 1s 46us/step - loss: 0.3499 - acc: 0.8980 - val_loss: 0.2335 - val_acc: 0.9335\n",
      "Epoch 9/50\n",
      "16000/16000 [==============================] - 1s 48us/step - loss: 0.3232 - acc: 0.9073 - val_loss: 0.2218 - val_acc: 0.9352\n",
      "Epoch 10/50\n",
      "16000/16000 [==============================] - 1s 54us/step - loss: 0.2985 - acc: 0.9138 - val_loss: 0.2083 - val_acc: 0.9403\n",
      "Epoch 11/50\n",
      "16000/16000 [==============================] - 1s 69us/step - loss: 0.2791 - acc: 0.9206 - val_loss: 0.2036 - val_acc: 0.9422\n",
      "Epoch 12/50\n",
      "16000/16000 [==============================] - 1s 69us/step - loss: 0.2579 - acc: 0.9258 - val_loss: 0.1855 - val_acc: 0.9458\n",
      "Epoch 13/50\n",
      "16000/16000 [==============================] - 1s 60us/step - loss: 0.2460 - acc: 0.9302 - val_loss: 0.1887 - val_acc: 0.9450\n",
      "Epoch 14/50\n",
      "16000/16000 [==============================] - 1s 71us/step - loss: 0.2364 - acc: 0.9298 - val_loss: 0.1795 - val_acc: 0.9468\n",
      "Epoch 15/50\n",
      "16000/16000 [==============================] - 1s 73us/step - loss: 0.2152 - acc: 0.9391 - val_loss: 0.1713 - val_acc: 0.9500\n",
      "Epoch 16/50\n",
      "16000/16000 [==============================] - 1s 70us/step - loss: 0.2201 - acc: 0.9356 - val_loss: 0.1648 - val_acc: 0.9505\n",
      "Epoch 17/50\n",
      "16000/16000 [==============================] - 1s 58us/step - loss: 0.1976 - acc: 0.9440 - val_loss: 0.1639 - val_acc: 0.9555\n",
      "Epoch 18/50\n",
      "16000/16000 [==============================] - 1s 53us/step - loss: 0.1921 - acc: 0.9442 - val_loss: 0.1624 - val_acc: 0.9540\n",
      "Epoch 19/50\n",
      "16000/16000 [==============================] - 1s 55us/step - loss: 0.1842 - acc: 0.9449 - val_loss: 0.1602 - val_acc: 0.9563\n",
      "Epoch 20/50\n",
      "16000/16000 [==============================] - 1s 53us/step - loss: 0.1795 - acc: 0.9471 - val_loss: 0.1560 - val_acc: 0.9525\n",
      "Epoch 21/50\n",
      "16000/16000 [==============================] - 1s 54us/step - loss: 0.1779 - acc: 0.9492 - val_loss: 0.1545 - val_acc: 0.9585\n",
      "Epoch 22/50\n",
      "16000/16000 [==============================] - 1s 57us/step - loss: 0.1632 - acc: 0.9528 - val_loss: 0.1562 - val_acc: 0.9540\n",
      "Epoch 23/50\n",
      "16000/16000 [==============================] - 1s 56us/step - loss: 0.1605 - acc: 0.9521 - val_loss: 0.1546 - val_acc: 0.9590\n",
      "Epoch 24/50\n",
      "16000/16000 [==============================] - 1s 69us/step - loss: 0.1559 - acc: 0.9535 - val_loss: 0.1503 - val_acc: 0.9613\n",
      "Epoch 25/50\n",
      "16000/16000 [==============================] - 1s 78us/step - loss: 0.1406 - acc: 0.9594 - val_loss: 0.1488 - val_acc: 0.9588\n",
      "Epoch 26/50\n",
      "16000/16000 [==============================] - 1s 77us/step - loss: 0.1482 - acc: 0.9570 - val_loss: 0.1484 - val_acc: 0.9572\n",
      "Epoch 27/50\n",
      "16000/16000 [==============================] - 1s 72us/step - loss: 0.1434 - acc: 0.9591 - val_loss: 0.1503 - val_acc: 0.9593\n",
      "Epoch 28/50\n",
      "16000/16000 [==============================] - 1s 81us/step - loss: 0.1398 - acc: 0.9587 - val_loss: 0.1491 - val_acc: 0.9603\n",
      "Epoch 29/50\n",
      "16000/16000 [==============================] - 1s 74us/step - loss: 0.1297 - acc: 0.9611 - val_loss: 0.1518 - val_acc: 0.9583\n",
      "Epoch 30/50\n",
      "16000/16000 [==============================] - 1s 66us/step - loss: 0.1344 - acc: 0.9613 - val_loss: 0.1465 - val_acc: 0.9593\n",
      "Epoch 31/50\n",
      "16000/16000 [==============================] - 1s 76us/step - loss: 0.1296 - acc: 0.9612 - val_loss: 0.1525 - val_acc: 0.9563\n",
      "Epoch 32/50\n",
      "16000/16000 [==============================] - 1s 84us/step - loss: 0.1234 - acc: 0.9638 - val_loss: 0.1411 - val_acc: 0.9595\n",
      "Epoch 33/50\n",
      "16000/16000 [==============================] - 1s 81us/step - loss: 0.1259 - acc: 0.9618 - val_loss: 0.1444 - val_acc: 0.9623\n",
      "Epoch 34/50\n",
      "16000/16000 [==============================] - 1s 80us/step - loss: 0.1161 - acc: 0.9660 - val_loss: 0.1430 - val_acc: 0.9600\n",
      "Epoch 35/50\n",
      "16000/16000 [==============================] - 1s 72us/step - loss: 0.1155 - acc: 0.9653 - val_loss: 0.1420 - val_acc: 0.9595\n",
      "Epoch 36/50\n",
      "16000/16000 [==============================] - 1s 74us/step - loss: 0.1125 - acc: 0.9668 - val_loss: 0.1450 - val_acc: 0.9633\n",
      "Epoch 37/50\n",
      "16000/16000 [==============================] - 1s 56us/step - loss: 0.1117 - acc: 0.9673 - val_loss: 0.1506 - val_acc: 0.9600\n",
      "Epoch 38/50\n",
      "16000/16000 [==============================] - 1s 65us/step - loss: 0.1102 - acc: 0.9659 - val_loss: 0.1505 - val_acc: 0.9603\n",
      "Epoch 39/50\n",
      "16000/16000 [==============================] - 1s 52us/step - loss: 0.1103 - acc: 0.9666 - val_loss: 0.1383 - val_acc: 0.9613\n",
      "Epoch 40/50\n",
      "16000/16000 [==============================] - 1s 50us/step - loss: 0.1048 - acc: 0.9688 - val_loss: 0.1422 - val_acc: 0.9630\n",
      "Epoch 41/50\n",
      "16000/16000 [==============================] - 1s 57us/step - loss: 0.0997 - acc: 0.9706 - val_loss: 0.1521 - val_acc: 0.9588\n",
      "Epoch 42/50\n",
      "16000/16000 [==============================] - 1s 51us/step - loss: 0.1048 - acc: 0.9691 - val_loss: 0.1445 - val_acc: 0.9617\n",
      "Epoch 43/50\n",
      "16000/16000 [==============================] - 1s 53us/step - loss: 0.1020 - acc: 0.9684 - val_loss: 0.1460 - val_acc: 0.9635\n",
      "Epoch 44/50\n",
      "16000/16000 [==============================] - 1s 52us/step - loss: 0.1005 - acc: 0.9679 - val_loss: 0.1447 - val_acc: 0.9650\n",
      "Epoch 45/50\n",
      "16000/16000 [==============================] - 1s 52us/step - loss: 0.0926 - acc: 0.9723 - val_loss: 0.1510 - val_acc: 0.9623\n",
      "Epoch 46/50\n",
      "16000/16000 [==============================] - 1s 52us/step - loss: 0.0954 - acc: 0.9708 - val_loss: 0.1481 - val_acc: 0.9660\n",
      "Epoch 47/50\n",
      "16000/16000 [==============================] - 1s 56us/step - loss: 0.0895 - acc: 0.9733 - val_loss: 0.1500 - val_acc: 0.9638\n",
      "Epoch 48/50\n",
      "16000/16000 [==============================] - 1s 48us/step - loss: 0.0893 - acc: 0.9724 - val_loss: 0.1540 - val_acc: 0.9615\n",
      "Epoch 49/50\n",
      "16000/16000 [==============================] - 1s 52us/step - loss: 0.0855 - acc: 0.9715 - val_loss: 0.1419 - val_acc: 0.9645\n",
      "Epoch 50/50\n",
      "16000/16000 [==============================] - 1s 55us/step - loss: 0.0807 - acc: 0.9740 - val_loss: 0.1538 - val_acc: 0.9625\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a23bcab70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 38us/step\n",
      "[0.13572957476451994, 0.9665]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.optimizers import SGD\n",
    "from keras import backend as K\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(123)\n",
    "\n",
    "'''\n",
    "データの生成\n",
    "'''\n",
    "mnist = datasets.fetch_mldata('MNIST original', data_home='.')\n",
    "\n",
    "n = len(mnist.data)\n",
    "N = 30000  # MNISTの一部を使う\n",
    "N_train = 20000\n",
    "N_validation = 4000\n",
    "indices = np.random.permutation(range(n))[:N]  # ランダムにN枚を選択\n",
    "\n",
    "X = mnist.data[indices]\n",
    "y = mnist.target[indices]\n",
    "Y = np.eye(10)[y.astype(int)]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = \\\n",
    "    train_test_split(X, Y, train_size=N_train)\n",
    "X_train, X_validation, Y_train, Y_validation = \\\n",
    "    train_test_split(X_train, Y_train, test_size=N_validation)\n",
    "\n",
    "'''\n",
    "モデル設定\n",
    "'''\n",
    "n_in = len(X[0])  # 784\n",
    "n_hiddens = [200, 200, 200]\n",
    "n_out = len(Y[0])  # 10\n",
    "p_keep = 0.5\n",
    "activation = 'relu'\n",
    "\n",
    "\n",
    "def weight_variable(shape):\n",
    "    return K.truncated_normal(shape, stddev=0.01)\n",
    "    # return np.random.normal(scale=0.01, size=shape)\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "for i, input_dim in enumerate(([n_in] + n_hiddens)[:-1]):\n",
    "    model.add(Dense(n_hiddens[i], input_dim=input_dim,\n",
    "                    kernel_initializer=weight_variable))\n",
    "    model.add(Activation(activation))\n",
    "    model.add(Dropout(p_keep))\n",
    "\n",
    "model.add(Dense(n_out, kernel_initializer=weight_variable))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=SGD(lr=0.01),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "'''\n",
    "モデル学習\n",
    "'''\n",
    "epochs = 50\n",
    "batch_size = 200\n",
    "\n",
    "hist = model.fit(X_train, Y_train, epochs=epochs,\n",
    "                 batch_size=batch_size,\n",
    "                 validation_data=(X_validation, Y_validation))\n",
    "\n",
    "'''\n",
    "学習の進み具合を可視化\n",
    "'''\n",
    "val_acc = hist.history['val_acc']\n",
    "val_loss = hist.history['val_loss']\n",
    "\n",
    "plt.rc('font', family='serif')\n",
    "fig = plt.figure()\n",
    "plt.plot(range(epochs), val_acc, label='acc', color='black')\n",
    "plt.xlabel('epochs')\n",
    "plt.show()\n",
    "# plt.savefig('mnist_keras.eps')\n",
    "\n",
    "'''\n",
    "予測精度の評価\n",
    "'''\n",
    "loss_and_metrics = model.evaluate(X_test, Y_test)\n",
    "print(loss_and_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
