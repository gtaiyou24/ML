# 5章 推測
一般化線形モデルにおける**<font color="blue">信頼区間推定</font>**と**<font color="blue">仮説検定</font>**の導出およびその利用について論じる.

<!-- MarkdownTOC -->

- 5.2 スコア統計量の標本分布
        - 標本分布
- 5.3 テイラー級数近似
        - 対数尤度関数
        - スコア関数
- 5.4 最尤推定量の標本分布
        - 標本分布
- 5.5 対数尤度比統計量
        - 飽和モデル\(最大モデル,フルモデル\)
        - 尤度比と対数尤度差
- 5.6 逸脱度の標本分布
        - 標本分布
- 5.7 仮説検定
    - パラメータベクトルに関する仮説検定
    - 2つのモデルの当てはまりの良さに関する仮説検定

<!-- /MarkdownTOC -->


| 統計的推測 | 説明 |
|:-----------------------------:|:------------------------|
| **信頼区間推定**<br>(*confidence interval estimation*)  | 母集団におけるある値$Y$は、$Y_{upper}$と$Y_{lower}$の間の値であることが$1-\alpha(<=1)$確かである. |
| **仮説検定**<br>(*hypothesis test*) | 統計モデル化の枠組みにおける**仮説検定**は、2つの関連するモデルが**<font color="blue">データにいかによく当てはまるか</font>**を比べることによってなされる.<br>たとえば、モデルの線形成分を他方よりも多くのパラメータを持つモデルと単純なモデルで同じぐらいデータに当てはまるか否やの検定を行う. |

仮説検定では、上記のような比較を行うために、**<u>モデルがいかによくデータに当てはまるかを表す要約統計量を用いる</u>**. こうした適合のよさを測る**<font color="blue">適合度統計量</font>**(*goodness of fit statistic*)は、尤度関数の最大値、対数尤度関数の最大値、平方和基準の最小値、残差にもとづく複合型の統計量などを基礎として構築される.

そのプロセスと論理は以下のように要約できる.

| ステップ | 説明 |
|:-------:|:----|
| 1 | 仮説$H_{0}$に対するモデル$M_{0}$とより一般的なモデル$M_{1}$を規定する($M_{0}$は$M_{1}$の特別な場合とする) |
| 2 | $M_{0}$を当てはめ、適合のよさを測る統計量$G_{0}$を計算する. <br>$M_{1}$を当てはめ、適合のよさを測る統計量$G_{1}$を計算する. |
| 3 | 適合のよさの改善を計算する. $G_{1} - G_{0}$を用いることが多いが,$G_{1}/G_{0}$を用いる場合もある. |
| 4 | 対立仮説$G_{1} \neq G_{0}$に対して帰無仮説$G_{1} = G_{0}$を検定するため、$G_{1} - G_{0}$(もしくは関連する統計量)の標本分布を用いる. |
| 5 | もし仮説$G_{1} = G_{0}$が棄却されなければ$H_{0}$は棄却されず、$M_{0}$がより良いモデルとなる.<br>もし仮説$G_{1} = G_{0}$が棄却されれば$H_{0}$が棄却され、$M_{1}$がより良いモデルとみなせる. |

推定と検定のどちらの推測の形でも、標本分布が要求される. すなわち信頼区間を計算するためには「**推定量の標本分布**」,仮説を検定するためには「**当てはまりのよさを測る統計量の標本分布**」が必要になる.

> もし反応変数が正規分布であれば推測に使われる標本分布は多くの場合、正確に求まる。その他の分布の場合は中心極限定理にもとづく大標本の漸近的な結果を用いなくてはならない。

<br>

> 基本的な考え方は、$S$が興味のある統計量であるならば、適当な条件の下で近似的に
>$$
\frac {S - E\left(S\right)}{\sqrt {\mathrm {var}\left( S \right)}} \sim N\left( 0, 1 \right)
$$
> または、同じ意味で
> $$
\frac { \left[ S - E\left( S \right) \right]^{2} }{ \mathrm {var}\left( S \right) } \sim \chi^{2}\left( 1 \right)
$$
> が成り立つことを示し、これを用いることである。ここに$E\left( S \right)$と$\mathrm {var}\left( S \right)$はそれぞれ$S$の漸近的な期待値と分散である。
>
> また、興味のある統計量がベクトル$\boldsymbol {s} = \left[ \begin{matrix} { S }_{ 1 } \\ \vdots  \\ { S }_{ p } \end{matrix} \right] $の場合には、漸近的な期待値$E\left( \boldsymbol {s} \right)$と分散共分散行列$\boldsymbol {\mathrm {V} }$（$\boldsymbol {\mathrm {V} }$は正則で逆行列$\boldsymbol {\mathrm {V} }^{-1}$が存在するとする）に対して近似的に
> $$
\left[ \boldsymbol {s} - E\left( \boldsymbol {s} \right) \right]^{T} \boldsymbol {\mathrm {V} }^{-1} \left[ \boldsymbol {s} - E\left( \boldsymbol {s} \right) \right] \sim \chi^{2}\left( p \right)
$$
> が成り立つことを示し、これを利用する。

---

## 5.2 スコア統計量の標本分布

| 項目 | 説明 |
|:----:|:----|
| 表記 | $Y_{1},\cdots,Y_{N}$ : パラメータ$\boldsymbol {\beta}$を持つ一般化線形モデルにおける**互いに独立な確率変数** |
| 仮定 | $E\left( Y_{i} \right) = \mu_{i}$と$g\left(\mu_{i}\right) = \mathrm {\boldsymbol {x}}_{i}^{T} \boldsymbol {\beta} = \eta_{i}$が成り立つとする.

| 項目 | 数式 | 備考 |
|:---:|:---------:|:----|
| 統計量 | $\mathrm {U}_{j} = \frac {\partial \log {\left( \boldsymbol {\beta} \right)}}{\partial \beta_{j}} = \sum _{i=1}^{N}{\left[ \cfrac { \left( { Y }_{ i }-{ \mu  }_{ i } \right)  }{ { var }\left( Y_{ i } \right)  } x_{ ij }\left( \cfrac { \partial \mu _{ i } }{ \partial \eta _{ i } }  \right)  \right] } , \quad j=1,\cdots,p$ | 「4章 推定」の<br>「スコア(ベクトル)統計量」を参照 |
| 期待値 | $E\left[\mathrm {U}_{j}\right] = 0, \quad j = 1,\cdots,p$ | 以下の証明を参照 |
| 分散(情報行列) | $\Im_{jk} = E\left[ \mathrm {U}_{j} \mathrm {U}_{k} \right]$ | スコア統計量の分散共分散行列<br>(=情報行列$\Im$)の要素 |

期待値の証明:<br>
スコア統計量$U_{j}$は、すべての$i$について$E\left(Y_{i}\right) = \mu_{i}$なので、
$$
E\left( U_{j} \right) = 0, \quad j = 1,\cdots,p
$$
となります. これは一般的な結果「3章 指数型分布族と一般化線形モデル」(25)に一致します.

#### 標本分布

**単一のパラメータ$\beta$のみがモデルに含まれる場合**、「3.3 指数型分布族の性質」節で示したように$E\left(U\right) = 0$かつ$\mathrm {var}\left( U \right) = \Im$であり、スコア統計量は慚近標本分布
$$
\frac {U}{\sqrt {\Im}} \sim N\left(0,1\right)
$$
または、
$$
\frac {U^{2}}{\Im} \sim \chi^{2}\left(1\right)
$$
を持つことが証明できる.


**パラメータのベクトル$\boldsymbol {\beta} = \left[ \begin{matrix} { \beta  }_{ 1 } \\ \vdots  \\ { \beta  }_{ p } \end{matrix} \right] $がモデルに含まれる場合**、スコアベクトル$\boldsymbol {\mathrm {U}} = \left[ \begin{matrix} \mathrm {U}_{ 1 } \\ \vdots  \\ { \mathrm {U} }_{ p } \end{matrix} \right]$は、漸近的に、多変量正規分布$\mathrm {\boldsymbol {U}} \sim \boldsymbol {\mathrm {N}}\left( 0, \Im \right)$に従い、大標本においては
$$
\boldsymbol {\mathrm {U}}^{T} \Im^{-1} \boldsymbol {\mathrm {U}} \sim \chi^{2}\left( p \right)
$$
が成り立つことが証明される。


## 5.3 テイラー級数近似
**様々な統計量について漸近的な標本分布を得るには、テイラー級数近似を使うのが便利である**。

> #### テイラー級数
> 単一の変数$x$に関する関数$f\left( x \right)$を値$t$のまわりでテイラー級数で近似すると、$x$が$t$に近いとき
> $$
f\left( x \right) = f\left( t \right) + (x - t)\left[ \cfrac {df}{dx} \right]_{x = t} + \frac {1}{2}(x - t)^{2}\left[ \cfrac {d^{2}f}{{dx}^{2}} \right]_{x = t} + \cdots
$$
> と表される.

#### 対数尤度関数

単一のパラメータ$\beta$の対数尤度関数に対して、推定値$b$の近くでテイラー級数近似を行うと、最初の3項は
$$
\log {L\left( \beta \right)} = \log {L\left( b \right)} + (\beta - b) \mathrm {U}\left( b \right) + \frac {1}{2} (\beta - b)^{2} \mathrm {U^{\prime}}\left( b \right)
$$
となる。ここに$\mathrm {U}\left( b \right) = d\log {L\left( \beta \right)} / d \beta$は、$\beta = b$に対して計算されたスコア関数である。$\mathrm {U}^{\prime} = d^{2} \log {L} / { d\beta }^{2} $がその期待値$E\left( \mathrm {U}^{\prime} \right) = - \Im$によって近似できるなら、近似式は、
$$
\log {L\left( \beta \right)} = \log {L\left( b \right)} + (\beta - b) \mathrm {U}\left( b \right) - \frac {1}{2} (\beta - b)^{2} \Im \left( b \right)
$$
と書き換えられる。ここに$\Im \left( b \right)$は、$\beta = b$に対して計算された情報量である。

パラメータベクトル$\boldsymbol {\beta}$の対数尤度関数に対しては
$$
\log {L\left( \boldsymbol {\beta} \right)} = \log {L\left( \boldsymbol {b} \right)} + (\boldsymbol {\beta} - \boldsymbol {b})^{T} \boldsymbol {\mathrm {U}}\left( \boldsymbol {\mathrm {b}} \right) - \frac {1}{2} (\boldsymbol {\beta} - \boldsymbol {b})^{T} \Im\left( \boldsymbol {b} \right) (\boldsymbol {\beta} - \boldsymbol {b}) \quad (5.4)
$$
のような近似式となる。ここに$\boldsymbol {\mathrm {U}}$は、スコアベクトル、$\Im$は情報行列である。

#### スコア関数

単一のパラメータ$\beta$のスコア関数に対して、推定値$b$の近くでテイラー級数近似を行うと、最初の2項は
$$
\mathrm {U}\left( \beta \right) = \mathrm {U}\left( b \right) + ( \beta - b ) \mathrm {U}^{\prime}\left( b \right)
$$
となる。$\mathrm {U}^{\prime}$が$E\left( \mathrm {U}^{\prime} \right) = - \Im$で近似できるとき
$$
\mathrm {U}\left( \beta \right) = \mathrm {U}\left(b\right) - (\beta - b) \Im\left( b \right)
$$
が得られる。パラメータベクトル$\beta$に対応する近似式は次のようになる。
$$
\boldsymbol {\mathrm {U}}\left( \boldsymbol {\beta} \right) = \boldsymbol {\mathrm {U}}\left( \boldsymbol {\mathrm {b}} \right) - \Im\left( \boldsymbol {\mathrm {b}} \right) (\boldsymbol {\mathrm {\beta}} - \boldsymbol {\mathrm {b}}) \quad (5.5)
$$

## 5.4 最尤推定量の標本分布
> 式(5.5)は最尤推定量$\boldsymbol {\mathrm {b}} = \hat {\boldsymbol {\beta}}$の標本分布を得るのに用いることができる。

| 項目 | 数式 | 備考 |
|:---:|:---------:|:----|
| 統計量 | $\boldsymbol {\mathrm {b}}$ |  |
| 期待値 | $E\left( \boldsymbol {\mathrm {b}} \right) = \boldsymbol {\mathrm {\beta}}$ |  |
| 分散(情報行列) | $\mathrm {var}\left( \boldsymbol {\mathrm {b}} \right) = E\left[ \left( \boldsymbol {\mathrm {b}} - \boldsymbol {\mathrm {\beta}} \right) \left( \boldsymbol {\mathrm {b}} - \boldsymbol {\mathrm {\beta}} \right)^{T} \right] = \Im^{-1}$ |  |

期待値の証明:<br>
式(5.5)を用いて期待値を示す。
> $$
\boldsymbol {\mathrm {U}}\left( \boldsymbol {\beta} \right) = \boldsymbol {\mathrm {U}}\left( \boldsymbol {\mathrm {b}} \right) - \Im\left( \boldsymbol {\mathrm {b}} \right) (\boldsymbol {\mathrm {\beta}} - \boldsymbol {\mathrm {b}}) \quad (5.5)
$$

定義より、$\boldsymbol {\mathrm {b}}$は$\log {L\left( \boldsymbol {\mathrm {b}} \right)}$を最大にする推定量であるから$\boldsymbol {\mathrm {U}}\left( \boldsymbol {\mathrm {b}} \right) = 0$。ゆえに
$$
\boldsymbol {\mathrm {U}}\left( \boldsymbol {\beta} \right) = - \Im\left( \boldsymbol {\mathrm {b}} \right) (\boldsymbol {\mathrm {\beta}} - \boldsymbol {\mathrm {b}})
$$
である。$\Im$が正則行列という条件のもとで
$$
\begin{eqnarray}
\Im^{-1} \boldsymbol {\mathrm {U}}\left( \boldsymbol {\beta} \right) & = & - \Im^{-1} \Im \left( \boldsymbol {\mathrm {b}} \right) (\boldsymbol {\mathrm {\beta}} - \boldsymbol {\mathrm {b}})\\
\Im^{-1} \boldsymbol {\mathrm {U}}\left( \boldsymbol {\beta} \right) & = & (\boldsymbol {\mathrm {b}} - \boldsymbol {\mathrm {\beta}})
\end{eqnarray}
$$
となる。$\Im$が定数とみなされるならばスコア統計量の期待値より$E\left( \boldsymbol {\mathrm {U}} \right) = 0$だから$E\left( \boldsymbol {\mathrm {b}} - \boldsymbol {\mathrm {\beta}} \right) = 0$。ゆえに少なくとも漸近的に$E\left( \boldsymbol {\mathrm {b}} - \beta \right) = 0$、すなわち、$\boldsymbol {\mathrm {b}}$は$\beta$の一致推定量である。

分散の証明:<br>
$\boldsymbol {\Im} = E\left( \boldsymbol {\mathrm {U}} \boldsymbol {\mathrm {U}}^{T} \right)$であり、また$\boldsymbol {\Im}$の対称性より$\left( \Im^{-1} \right)^{T} = \Im^{-1}$だから、$\boldsymbol {\mathrm {b}}$の分散共分散行列は
$$
E\left[ (\boldsymbol {\mathrm {b}} - \beta)(\boldsymbol {\mathrm {b}} - \beta)^{T} \right] = \Im^{-1} E\left( \boldsymbol {\mathrm {U}} \boldsymbol {\mathrm {U}}^{T} \right) \Im^{-1} = \Im^{-1}
$$
である。

<img src="./imgs/05/最尤推定量の分散証明.png" width="70%">

#### 標本分布
最尤推定量の期待値と分散の定義から、
$$
\left( \boldsymbol {\mathrm {b}} - \beta \right)^{T} \Im\left( \boldsymbol {\mathrm {b}} \right) \left( \boldsymbol {\mathrm {b}} - \beta \right) \sim \chi^{2}\left( p \right) \quad (5.7)
$$
となる。これは**<font color="blue">ワルド統計量</font>(Wald statistic)**である。単一パラメータの場合に、しばしば
$$
\boldsymbol {\mathrm {b}} \sim N\left( \boldsymbol {\beta}, \boldsymbol {\Im}^{-1} \right) \quad (5.8)
$$
と表される。一般化線形モデルにおける反応変数が正規分布ならば、式(5.7)と(5.8)は正確な結果である。


---
## 5.5 対数尤度比統計量
> あるモデルの適切さを評価する1つの方法は、推定されうるパラメータの最大個数を含んだ**飽和モデル**(satuated model)と呼ばれる、最も一般的なモデルと興味のあるモデルを比べることである。ただし、興味のあるモデルと飽和モデルは同じ確率分布および連結関数をもつ一般化線形モデルとする。

#### 飽和モデル(最大モデル,フルモデル)
$N$個の線形成分$\boldsymbol {\mathrm {x}}_{i}^{T} \boldsymbol {\beta}$に対して$N$個の観測値$Y_{i}, i = 1,\dots,N$が得られているとする。このとき、飽和モデルは$N$個のパラメータで表される。

 - 飽和モデルは別名、**最大モデル**(maximal model)または**フルモデル**(full model)とも呼ばれる

観測値のいくつかが同じ線形成分(同じ共変量パターン)を持つ、すなわち、因子の水準組み合わせが同じであり、連続的な説明変数の値もすべて同じ値である、という場合、それらは**繰返し**(replicate)があると言われる。このとき、飽和モデルで推定できるパラメータの最大数は相異なる線形成分の数と等しい。それは$N$より小さい。

→説明変数ベクトル$i$と$j$の各要素が全て同じ値である場合、それらは繰返しがあると言われる。ということ

#### 尤度比と対数尤度差
表記

| 数式 | 説明 |
|:----:|:--------|
| $m$ | 飽和モデルのパラメータ数 |
| $\boldsymbol {\beta}_{\mathrm {max}}$ | 飽和モデルのパラメータベクトル |
| $\boldsymbol {\mathrm {b}}_{\mathrm {max}}$ | $\boldsymbol {\beta}_{\mathrm {max}}$の最尤推定量 |
| $L\left( { \boldsymbol {\mathrm {b}}_{\mathrm {max}} };{ \boldsymbol {y} } \right)$ | $\boldsymbol {\mathrm {b}}_{\mathrm {max}}$で評価した飽和モデルの尤度関数 |

$L\left( { \boldsymbol {\mathrm {b}}_{\mathrm {max}} };{ \boldsymbol {y} } \right)$は、観測値に対して同じ分布と同じ連結関数を持つ、他のどの尤度関数よりも大きくなる。なぜなら、飽和モデルが最も完全にデータを記述しているからである。

$L\left( { \boldsymbol {\mathrm {b}}_{\mathrm {max}} };{ \boldsymbol {y} } \right)$を関心のあるモデルの尤度関数の最大値とする。そのとき、尤度比
$$
\lambda = \frac { L\left( { \boldsymbol {\mathrm {b}}_{\mathrm {max}} };{ \boldsymbol {y} } \right) }{ L\left( { \boldsymbol {\mathrm {b}} };{ \boldsymbol {y} } \right) }
$$
がモデルの適合度を測る1つの方法を与える。実際には、対数尤度関数の差
$$
\log {\lambda} = \log {L\left( { \boldsymbol {\mathrm {b}}_{\mathrm {max}} };{ \boldsymbol {y} } \right)} - \log {L\left( { \boldsymbol {\mathrm {b}} };{ \boldsymbol {y} } \right)}
$$
が使われる。

 - $\log {\lambda}$が大きいいとき、関心のあるモデルは飽和モデルに比べてあまりよくデータを記述していないことを示唆する。
 - $\log {\lambda}$の棄却域を決めるためには標本分布が必要である

次節では、$2\log {\lambda}$がカイ二乗分布を持つことを確認する。それゆえ$\log {\lambda}$よりむしろ$2 \log {\lambda}$が一般的に使われる統計量である。(*Nelder and Wedderburn(1972*)はこれを**<font color="blue">逸脱度</font>(deviance)**と呼んでいる。)


## 5.6 逸脱度の標本分布
> 逸脱度は、**<font color="blue">対数尤度比統計量</font>**(log likehood (ratio) statistic)とも呼ばれ、次のように定義される
$$
D = 2 \left[ \log {L\left( { \boldsymbol {\mathrm {b}}_{\mathrm {max}} };{ \boldsymbol {y} } \right)} - \log {L\left( { \boldsymbol {\mathrm {b}} };{ \boldsymbol {y} } \right)} \right]
$$

$\boldsymbol {\mathrm {b}}$がパラメータ$\boldsymbol {\beta}$の最尤推定量ならば、（$\boldsymbol {\mathrm {U}}\left( \boldsymbol {\mathrm {b}} \right) = \boldsymbol {0}$だから）式(5.4)より、近似的に
$$
\log {L\left( \boldsymbol {\beta} \right)} - \log {L\left( \boldsymbol {\mathrm {b}} \right)} = - \frac {1}{2} \left( \boldsymbol {\beta} - \boldsymbol {\mathrm {b}} \right)^{T} \boldsymbol {\Im}\left( \boldsymbol {\mathrm {b}} \right) \left( \boldsymbol {\beta} - \boldsymbol {\mathrm {b}} \right)
$$
の関係が成り立つ。したがって、
$$
2 \left[ \log {L\left( \boldsymbol {\mathrm {b}};\boldsymbol {\mathrm {y}} \right)} - \log {L\left( \boldsymbol {\beta};\boldsymbol {\mathrm {y}} \right)} \right] = \left( \boldsymbol {\beta} - \boldsymbol {\mathrm {b}} \right)^{T} \boldsymbol {\Im}\left( \boldsymbol {\mathrm {b}} \right) \left( \boldsymbol {\beta} - \boldsymbol {\mathrm {b}} \right)
$$
となり、式(5.7)より自由度$p$のカイ2乗分布$\chi^{2}\left( p \right)$に従う。ただし、$p$は関心のあるモデルに含まれるパラメータ数である。

#### 標本分布
上記の結果から逸脱度
$$
\begin{eqnarray}
D & = & 2 \left[ \log {L\left({ \boldsymbol {\mathrm {b_{max}}} };{ \boldsymbol {\mathrm {y}} }\right)} - \log {L\left({ \boldsymbol {\mathrm {b} }};{ \boldsymbol {\mathrm {y}} }\right)} \right]  \\
  & = &  2 \left[ \log {L\left({ \boldsymbol {\mathrm {b_{max}}} };{ \boldsymbol {\mathrm {y}} }\right)} - \log {L\left({ \boldsymbol {\mathrm {\beta_{max}}} };{ \boldsymbol {\mathrm {y}} }\right)} \right]
  - 2 \left[ \log {L\left({ \boldsymbol {\mathrm {b} }};{ \boldsymbol {\mathrm {y}} }\right)} - \log {L\left({ \boldsymbol {\mathrm {\beta} }};{ \boldsymbol {\mathrm {y}} }\right)} \right]
  + 2 \left[ \log {L\left({ \boldsymbol {\mathrm {\beta_{max}}} };{ \boldsymbol {\mathrm {y}} }\right)}  - \log {L\left({ \boldsymbol {\mathrm {\beta} }};{ \boldsymbol {\mathrm {y}} }\right)} \right]
\end{eqnarray}
$$
の標本分布が導かれる。

 - 上式の角括弧の第1項は、${\chi}^{2}\left( m \right)$に従う。
 	- $m$ : 飽和モデルでのパラメータ数
 - 上式の角括弧の第2項は、${\chi}^{2}\left( p \right)$に従う。
 	- $p$ : 関心のあるモデルにおけるパラメータ数
 - 上式の角括弧の第3項の$\upsilon = 2 \left[ \log {L\left( \boldsymbol {\beta_{\mathrm {max}}};\boldsymbol {\mathrm {y}} \right)} - \log {L\left( {\boldsymbol {\beta}};{\boldsymbol {\mathrm {y}}} \right)} \right]$は関心のあるモデルが飽和モデルと同じくらい当てはまりが良いときゼロに近い正の定数である。

それゆえ、1.5節の結果(性質6)より逸脱度の標本分布は、近似的に
$$
D \sim {\chi}^{2}\left( m - p, \upsilon \right)
$$
である。ただし$\upsilon$は非心パラメータである。

> 反応変数$Y_{i}$が、正規分布に従うとき、$D$は正確にカイ2乗分布に従う。しかし、このとき$D$は、実際上、未知である$\mathrm {var}\left( Y_{i} \right) = \sigma^{2}$に依存する。このことは$D$が適合度を測る統計量として直接には使えないことを意味する。


> $Y_{i}$が他の分布に従うときには、$D$の標本分布は近似的にカイ2乗分布となる。しかし、二項分布やポアソン分布などの場合、$D$は実際に計算でき、適合度を測る統計量としてそのまま利用することができる。


---
## 5.7 仮説検定

### パラメータベクトルに関する仮説検定
> 長さ$p$のパラメータベクトル$\boldsymbol {\mathrm {\beta}}$に関する仮説は、**ワルド統計量**$\left( \hat {\boldsymbol {\beta}} - \boldsymbol {\beta} \right)^{T} \boldsymbol {\Im}\left( \hat {\boldsymbol {\beta}} - \boldsymbol {\beta} \right) \sim {\chi}^{2}\left( p \right)$を用いて検定できる。

### 2つのモデルの当てはまりの良さに関する仮説検定
> 2つのモデルは、同じ確率分布および連結関数を持ち、単純な方のモデル$M_{0}$の線形成分が、より一般的なモデル$M_{1}$の線形成分の特別な場合となっていなければならない。

モデル$M_{0}$に対応する帰無仮説
$$
H_{0} \mathrm {:} \boldsymbol {\beta} = \boldsymbol {\beta}_{0} = \left[ \begin{matrix} { \beta  }_{ 1 } \\ \vdots  \\ { \beta  }_{ q } \end{matrix} \right]
$$
と、モデル$M_{1}$に対応する、より一般的な仮説
$$
H_{1} \mathrm {:} \boldsymbol {\beta} = \boldsymbol {\beta}_{1} = \left[ \begin{matrix} { \beta  }_{ 1 } \\ \vdots  \\ { \beta  }_{ p } \end{matrix} \right]
$$
を考える。ここに、$q < p < N$である。

WIP